{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow as tf    \n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, LSTM, Input, concatenate, SimpleRNN, Dropout, Bidirectional, Embedding, GRU\n",
    "from keras.callbacks import History\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "history = History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Data\\\\Processed_M3\\\\Sites_10min_time_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>site</th>\n",
       "      <th>timeInterval</th>\n",
       "      <th>occupancy0</th>\n",
       "      <th>speed0</th>\n",
       "      <th>volume0</th>\n",
       "      <th>dateTime</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayOfWeek</th>\n",
       "      <th>dayType</th>\n",
       "      <th>density0</th>\n",
       "      <th>state0</th>\n",
       "      <th>interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>14005 WB P0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>67.728571</td>\n",
       "      <td>2016-07-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>14005 WB P0</td>\n",
       "      <td>00:10:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>62.821429</td>\n",
       "      <td>2016-07-01 00:10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>14005 WB P0</td>\n",
       "      <td>00:20:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>53.171429</td>\n",
       "      <td>2016-07-01 00:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>14005 WB P0</td>\n",
       "      <td>00:30:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>51.971429</td>\n",
       "      <td>2016-07-01 00:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>14005 WB P0</td>\n",
       "      <td>00:40:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>44.350000</td>\n",
       "      <td>2016-07-01 00:40:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51403</th>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>14063 WB P0</td>\n",
       "      <td>23:10:00</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>97.012222</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>2016-08-21 23:10:00</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.260833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51404</th>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>14063 WB P0</td>\n",
       "      <td>23:20:00</td>\n",
       "      <td>0.436667</td>\n",
       "      <td>96.243056</td>\n",
       "      <td>78.750000</td>\n",
       "      <td>2016-08-21 23:20:00</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.618611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51405</th>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>14063 WB P0</td>\n",
       "      <td>23:30:00</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>96.452778</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>2016-08-21 23:30:00</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.694167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51406</th>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>14063 WB P0</td>\n",
       "      <td>23:40:00</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>96.370833</td>\n",
       "      <td>70.687500</td>\n",
       "      <td>2016-08-21 23:40:00</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51407</th>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>14063 WB P0</td>\n",
       "      <td>23:50:00</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>99.927083</td>\n",
       "      <td>61.312500</td>\n",
       "      <td>2016-08-21 23:50:00</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51408 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date         site timeInterval  occupancy0      speed0  \\\n",
       "0      2016-07-01  14005 WB P0     00:00:00    0.000000  100.000000   \n",
       "1      2016-07-01  14005 WB P0     00:10:00    0.000000  100.000000   \n",
       "2      2016-07-01  14005 WB P0     00:20:00    0.000000  100.000000   \n",
       "3      2016-07-01  14005 WB P0     00:30:00    0.000000  100.000000   \n",
       "4      2016-07-01  14005 WB P0     00:40:00    0.000000  100.000000   \n",
       "...           ...          ...          ...         ...         ...   \n",
       "51403  2016-08-21  14063 WB P0     23:10:00    0.890000   97.012222   \n",
       "51404  2016-08-21  14063 WB P0     23:20:00    0.436667   96.243056   \n",
       "51405  2016-08-21  14063 WB P0     23:30:00    0.490000   96.452778   \n",
       "51406  2016-08-21  14063 WB P0     23:40:00    0.520000   96.370833   \n",
       "51407  2016-08-21  14063 WB P0     23:50:00    0.240000   99.927083   \n",
       "\n",
       "         volume0             dateTime  hour  dayOfWeek  dayType  density0  \\\n",
       "0      67.728571  2016-07-01 00:00:00     0          4        0  0.000000   \n",
       "1      62.821429  2016-07-01 00:10:00     0          4        0  0.000000   \n",
       "2      53.171429  2016-07-01 00:20:00     0          4        0  0.000000   \n",
       "3      51.971429  2016-07-01 00:30:00     0          4        0  0.000000   \n",
       "4      44.350000  2016-07-01 00:40:00     0          4        0  0.000000   \n",
       "...          ...                  ...   ...        ...      ...       ...   \n",
       "51403  62.000000  2016-08-21 23:10:00    23          6        1  1.260833   \n",
       "51404  78.750000  2016-08-21 23:20:00    23          6        1  0.618611   \n",
       "51405  36.000000  2016-08-21 23:30:00    23          6        1  0.694167   \n",
       "51406  70.687500  2016-08-21 23:40:00    23          6        1  0.736667   \n",
       "51407  61.312500  2016-08-21 23:50:00    23          6        1  0.340000   \n",
       "\n",
       "       state0  interval  \n",
       "0         0.0         0  \n",
       "1         0.0         1  \n",
       "2         0.0         2  \n",
       "3         0.0         3  \n",
       "4         0.0         4  \n",
       "...       ...       ...  \n",
       "51403     0.0       139  \n",
       "51404     0.0       140  \n",
       "51405     0.0       141  \n",
       "51406     0.0       142  \n",
       "51407     0.0       143  \n",
       "\n",
       "[51408 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeInterval = '10min_time'\n",
    "# df.columns = ['date', 'site', timeInterval, 'occupancy0', 'speed0', 'volume0','dateTime', 'hour', 'dayOfWeek', 'dayType']\n",
    "df.columns = ['date','site','timeInterval','occupancy0','speed0','volume0','dateTime','hour','dayOfWeek','dayType','density0','state0']\n",
    "sites = set(df['site'])\n",
    "dateTime = pd.to_datetime(df['dateTime'])\n",
    "df['interval'] = [v.hour*6+int(v.minute/10) for v in dateTime]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'site', 'timeInterval', 'occupancy0', 'speed0', 'volume0', 'dateTime', 'hour', 'dayOfWeek', 'dayType', 'density0', 'state0', 'interval', 'volume71', 'hour71', 'dayOfWeek71', 'interval71', 'dayType71']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>site</th>\n",
       "      <th>timeInterval</th>\n",
       "      <th>occupancy0</th>\n",
       "      <th>speed0</th>\n",
       "      <th>volume0</th>\n",
       "      <th>dateTime</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayOfWeek</th>\n",
       "      <th>dayType</th>\n",
       "      <th>density0</th>\n",
       "      <th>state0</th>\n",
       "      <th>interval</th>\n",
       "      <th>volume71</th>\n",
       "      <th>hour71</th>\n",
       "      <th>dayOfWeek71</th>\n",
       "      <th>interval71</th>\n",
       "      <th>dayType71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>14037 WB P0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>94.034788</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>2016-07-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.643333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>14037 WB P0</td>\n",
       "      <td>00:10:00</td>\n",
       "      <td>1.323333</td>\n",
       "      <td>91.695000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>2016-07-01 00:10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.874722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>14037 WB P0</td>\n",
       "      <td>00:20:00</td>\n",
       "      <td>1.168333</td>\n",
       "      <td>94.034167</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>2016-07-01 00:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.655139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>14037 WB P0</td>\n",
       "      <td>00:30:00</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>95.485000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>2016-07-01 00:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.267917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>14037 WB P0</td>\n",
       "      <td>00:40:00</td>\n",
       "      <td>1.328333</td>\n",
       "      <td>94.121111</td>\n",
       "      <td>92.571429</td>\n",
       "      <td>2016-07-01 00:40:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.881806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51115</th>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>14049 WB P0</td>\n",
       "      <td>23:10:00</td>\n",
       "      <td>1.492500</td>\n",
       "      <td>97.194861</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>2016-08-21 23:10:00</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.114375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139</td>\n",
       "      <td>915.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51116</th>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>14049 WB P0</td>\n",
       "      <td>23:20:00</td>\n",
       "      <td>1.210000</td>\n",
       "      <td>95.399306</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>2016-08-21 23:20:00</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.714167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51117</th>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>14049 WB P0</td>\n",
       "      <td>23:30:00</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>97.567698</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>2016-08-21 23:30:00</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.381250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141</td>\n",
       "      <td>928.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51118</th>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>14049 WB P0</td>\n",
       "      <td>23:40:00</td>\n",
       "      <td>1.185000</td>\n",
       "      <td>94.434008</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>2016-08-21 23:40:00</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.678750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142</td>\n",
       "      <td>996.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51119</th>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>14049 WB P0</td>\n",
       "      <td>23:50:00</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>97.252639</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>2016-08-21 23:50:00</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.402500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51408 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date         site timeInterval  occupancy0     speed0  \\\n",
       "432    2016-07-01  14037 WB P0     00:00:00    1.160000  94.034788   \n",
       "433    2016-07-01  14037 WB P0     00:10:00    1.323333  91.695000   \n",
       "434    2016-07-01  14037 WB P0     00:20:00    1.168333  94.034167   \n",
       "435    2016-07-01  14037 WB P0     00:30:00    0.895000  95.485000   \n",
       "436    2016-07-01  14037 WB P0     00:40:00    1.328333  94.121111   \n",
       "...           ...          ...          ...         ...        ...   \n",
       "51115  2016-08-21  14049 WB P0     23:10:00    1.492500  97.194861   \n",
       "51116  2016-08-21  14049 WB P0     23:20:00    1.210000  95.399306   \n",
       "51117  2016-08-21  14049 WB P0     23:30:00    0.975000  97.567698   \n",
       "51118  2016-08-21  14049 WB P0     23:40:00    1.185000  94.434008   \n",
       "51119  2016-08-21  14049 WB P0     23:50:00    0.990000  97.252639   \n",
       "\n",
       "          volume0             dateTime  hour  dayOfWeek  dayType  density0  \\\n",
       "432    134.000000  2016-07-01 00:00:00     0          4        0  1.643333   \n",
       "433    158.000000  2016-07-01 00:10:00     0          4        0  1.874722   \n",
       "434    136.000000  2016-07-01 00:20:00     0          4        0  1.655139   \n",
       "435    114.000000  2016-07-01 00:30:00     0          4        0  1.267917   \n",
       "436     92.571429  2016-07-01 00:40:00     0          4        0  1.881806   \n",
       "...           ...                  ...   ...        ...      ...       ...   \n",
       "51115  126.000000  2016-08-21 23:10:00    23          6        1  2.114375   \n",
       "51116  109.000000  2016-08-21 23:20:00    23          6        1  1.714167   \n",
       "51117   92.000000  2016-08-21 23:30:00    23          6        1  1.381250   \n",
       "51118   94.000000  2016-08-21 23:40:00    23          6        1  1.678750   \n",
       "51119   83.000000  2016-08-21 23:50:00    23          6        1  1.402500   \n",
       "\n",
       "       state0  interval  volume71  hour71  dayOfWeek71  interval71  dayType71  \n",
       "432       0.0         0       NaN     NaN          NaN         NaN        NaN  \n",
       "433       0.0         1       NaN     NaN          NaN         NaN        NaN  \n",
       "434       0.0         2       NaN     NaN          NaN         NaN        NaN  \n",
       "435       0.0         3       NaN     NaN          NaN         NaN        NaN  \n",
       "436       0.0         4       NaN     NaN          NaN         NaN        NaN  \n",
       "...       ...       ...       ...     ...          ...         ...        ...  \n",
       "51115     0.0       139     915.0    11.0          6.0        68.0        1.0  \n",
       "51116     0.0       140    1011.0    11.0          6.0        69.0        1.0  \n",
       "51117     0.0       141     928.0    11.0          6.0        70.0        1.0  \n",
       "51118     0.0       142     996.0    11.0          6.0        71.0        1.0  \n",
       "51119     0.0       143    1052.0    12.0          6.0        72.0        1.0  \n",
       "\n",
       "[51408 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The lag is the time distance between time-factors and time-target\n",
    "# If the lag is 0, we say we try to use the data 10 mins ago to forecast the now traffic condition\n",
    "# If the lag is 2, we say we try to use the data 30 mins ago to forecast the now traffic condition\n",
    "# If the lag is 5, we say we try to use the data 60 mins ago to forecast the now traffic condition\n",
    "\n",
    "window = 6*10\n",
    "lag = 11            # lag 11 means the label is 120 mins later\n",
    "lag = lag + window\n",
    "\n",
    "# lag_names = ['volume'+str(t) for t in range(lag+1)]\n",
    "volume_names = 'volume'+str(lag)\n",
    "hour_names = 'hour'+str(lag)\n",
    "dayOfWeek_names = 'dayOfWeek'+str(lag)\n",
    "interval_names = 'interval'+str(lag)\n",
    "dayType_names = 'dayType'+str(lag)\n",
    "data_features = [volume_names, hour_names, dayOfWeek_names, interval_names, dayType_names]\n",
    "\n",
    "column_names = list(df.columns.values) + data_features\n",
    "print(column_names)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "for site in sites:\n",
    "    df1 = df[df['site']==site]\n",
    "    df1.sort_values('dateTime')\n",
    "    # df1 = pd.concat([df1]+ [df1['volume0'].shift(t) for t in range(lag+1)], axis=1)\n",
    "    df1 = pd.concat([df1]+ [df1['volume0'].shift(lag)], axis=1)\n",
    "    df1 = pd.concat([df1]+ [df1['hour'].shift(lag)], axis=1)\n",
    "    df1 = pd.concat([df1]+ [df1['dayOfWeek'].shift(lag)], axis=1)\n",
    "    df1 = pd.concat([df1]+ [df1['interval'].shift(lag)], axis=1)\n",
    "    df1 = pd.concat([df1]+ [df1['dayType'].shift(lag)], axis=1)\n",
    "    data = data.append(df1)\n",
    "data.columns = column_names\n",
    "#data = data.dropna()\n",
    "\n",
    "features = ['volume' + str(lag)]\n",
    "features_name = 'volume' + str(lag)\n",
    "aux_features = [interval_names, dayType_names,hour_names, dayOfWeek_names]\n",
    "columns = features + aux_features\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Normalising Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(columns, df): #IMPORTANT: run this\n",
    "    \"\"\"\n",
    "    Normalise variables given the list 'columns'. Used for SVR model. \n",
    "    \n",
    "    Parameters:\n",
    "    columns (list): list of strings containing feature names that need to be normalised.\n",
    "    df (pandas dataframe): training data.\n",
    "    \n",
    "    \"\"\"\n",
    "    min_max_scaler = preprocessing.MinMaxScaler() #normalise to make variables comparable \n",
    "    final_df = pd.DataFrame(min_max_scaler.fit_transform(df[columns]), columns = columns)\n",
    "    \n",
    "    for col in df.columns: #add back the columns that weren't normalised\n",
    "        if col not in columns: \n",
    "            final_df[col] = df[col].values\n",
    "    \n",
    "#     if 'volume' in columns: #also store the unnormalised travel times if necessary \n",
    "#         final_df['volume_unnorm'] = df['volume'].values\n",
    "    \n",
    "    return final_df, min_max_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalise(predictions, scaler): #IMPORTANT: run this\n",
    "    \"\"\"\n",
    "    Denormalise the predictions back to the previous scale. \n",
    "    \"\"\"\n",
    "    predictions = predictions.reshape(1,-1)\n",
    "    pred = scaler.inverse_transform(predictions)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_auxiliary_input(train_x, test_x, features): \n",
    "    \"\"\"\n",
    "    Function to filter out only the auxiliary features. \n",
    "    Auxiliary features are all the other features other than the lagged features.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    train_x_aux = train_x[features]\n",
    "    test_x_aux = test_x[features]\n",
    "    \n",
    "    return train_x_aux, test_x_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ann_data(x):\n",
    "    \"\"\"\n",
    "    Reformat data to appropriate form for the recurrent neural\n",
    "    network.\n",
    "    \n",
    "    \"\"\"\n",
    "    train_x = []\n",
    "    for i in range(0, len(x)):\n",
    "        row = x.iloc[i][['volume1']].values\n",
    "        train_x.append(row)\n",
    "    return np.array(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Window the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_generator(x,y,lag,window):\n",
    "    \"\"\"\n",
    "    1. we assume the train test is dataframe format, \n",
    "    and it contains both time series and other features\n",
    "       \n",
    "    2. this is binary classification thus no normalization apply to label. \n",
    "    and we don't need the base line like time series forecasting\n",
    "    \n",
    "    3. both ANN and stats mode will be processed in same manner as (1,n_features).\n",
    "    it is a flatten version for multiple window input and can be accepted by both ANN and stats model.\n",
    "    \"\"\"\n",
    "    local_x = x.copy()\n",
    "    local_y = y.copy()\n",
    "    \n",
    "    index_x = local_x.reset_index().index\n",
    "    index_y = local_y.reset_index().index\n",
    "    data_n = len(x) - lag               # for 5 window 0 lag, means 5 time interval before points predict 1 time interval later.\n",
    "\n",
    "    y_windowed = []\n",
    "    x_windowed = []\n",
    "    \n",
    "    for i in range(data_n):\n",
    "        x_windowed.append(local_x[i : i+window].values.tolist())  # get features\n",
    "        y_windowed.append(local_y[index_y[i]])\n",
    "        if i == 0:\n",
    "            print()\n",
    "#             print(\"*    processing the time series \" + str(window) +\" window in lag \" + str(lag-window))\n",
    "#             print('features: ', local_x[i : i+window], ' in ', str(index_x[0]),  ' to ', str(index_x[0]+window))\n",
    "#             print('label: ', local_y[index_y[i]], ' in ', str(index_y[0]))\n",
    "\n",
    "    y_windowed = np.asarray(y_windowed).astype(np.float32)\n",
    "    \n",
    "    # reshape to (n_sample, n_feautre * n_length) still 2d\n",
    "    x_windowed = np.asarray(x_windowed).astype(np.float32)\n",
    "#     print('input shape before:', x_windowed.shape)\n",
    "#     #x_windowed = np.reshape(x_windowed, (x_windowed.shape[0],-1))\n",
    "#     print('input shape after:', x_windowed.shape)\n",
    "    \n",
    "    \n",
    "    return x_windowed, y_windowed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(x,y):\n",
    "#     print(\"accuracy_score\", accuracy_score(x,y))\n",
    "    print(metrics.classification_report(x,y))\n",
    "#     print(\"roc_auc_score: \", metrics.roc_auc_score(x,y))\n",
    "#     print(\"f1 score: \", metrics.f1_score(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 14037 WB P0\n",
      "\n",
      "\n",
      "\n",
      " 14011 WB P0\n",
      "\n",
      "\n",
      "\n",
      " 14005 WB P0\n",
      "\n",
      "\n",
      "\n",
      " 14063 WB P0\n",
      "\n",
      "\n",
      "\n",
      " 14025 WB P0\n",
      "\n",
      "\n",
      "\n",
      " 14055 WB P0\n",
      "\n",
      "\n",
      "\n",
      " 14049 WB P0\n",
      "\n",
      "\n",
      "Wall time: 19min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lstm_pre,lstm_test=[],[]\n",
    "\n",
    "\n",
    "\n",
    "for siteId in sites:\n",
    "    print('\\n',siteId)\n",
    "    tmp = data[data['site']==siteId]\n",
    "    tmp = tmp.dropna()\n",
    "    tmp = tmp.reset_index()\n",
    "    if len(tmp) == 0:\n",
    "        #print('error',siteId)\n",
    "        continue\n",
    "    \n",
    "    index = len(tmp) * 0.80\n",
    "    train = tmp.loc[:index]\n",
    "    test = tmp.loc[index-1:]\n",
    "    len(train)/len(tmp) * 100 \n",
    "    \n",
    "    ### Normalise all data (simulated and real accidents dataset) and create lags.\n",
    "    train_norm, _ = normalise(features,train)\n",
    "    test_norm, _ = normalise(features,test)\n",
    "\n",
    "    # this is a binary classification thus we don't normlize the label\n",
    "    y_train = train_norm['state0']\n",
    "    x_train = train_norm[features]\n",
    "    y_test = test_norm['state0']\n",
    "    x_test = test_norm[features]\n",
    "\n",
    "    x_train_win, y_train_win = window_generator(x_train,y_train,lag,window)\n",
    "    x_test_win, y_test_win = window_generator(x_test,y_test,lag,window)\n",
    "    \n",
    "#     x_train_win = np.reshape(x_train_win, (x_train_win.shape[0], x_train_win.shape[1]))\n",
    "#     x_test_win = np.reshape(x_test_win, (x_test_win.shape[0], x_test_win.shape[1]))  \n",
    "    \n",
    "    # LSTM\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(3))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    model.fit(x_train_win, y_train_win, epochs=100, verbose=0)\n",
    "    y_pred = model.predict(x_test_win)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    lstm_pre.extend(y_pred.tolist())\n",
    "    lstm_test.extend(y_test_win.tolist())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 14037 WB P0\n",
      "\n",
      "\n",
      "RNN\n",
      "LSTM\n",
      "BiLSTM\n",
      "GRU\n",
      "\n",
      " 14011 WB P0\n",
      "\n",
      "\n",
      "RNN\n",
      "LSTM\n",
      "BiLSTM\n",
      "GRU\n",
      "\n",
      " 14005 WB P0\n",
      "\n",
      "\n",
      "RNN\n",
      "LSTM\n",
      "BiLSTM\n",
      "GRU\n",
      "\n",
      " 14063 WB P0\n",
      "\n",
      "\n",
      "RNN\n",
      "LSTM\n",
      "BiLSTM\n",
      "GRU\n",
      "\n",
      " 14025 WB P0\n",
      "\n",
      "\n",
      "RNN\n",
      "LSTM\n",
      "BiLSTM\n",
      "GRU\n",
      "\n",
      " 14055 WB P0\n",
      "\n",
      "\n",
      "RNN\n",
      "LSTM\n",
      "BiLSTM\n",
      "GRU\n",
      "\n",
      " 14049 WB P0\n",
      "\n",
      "\n",
      "RNN\n",
      "LSTM\n",
      "BiLSTM\n",
      "GRU\n",
      "Wall time: 2h 29min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mrp_pre,mrp_test=[],[]\n",
    "lr_pre,lr_test=[],[]\n",
    "rf_pre,rf_test=[],[]\n",
    "svc_pre,svc_test=[],[]\n",
    "kn_pre,kn_test=[],[]\n",
    "xgb_pre,xgb_test=[],[]\n",
    "dl_pre,dl_test=[],[]\n",
    "rnn_pre,rnn_test=[],[]\n",
    "#lstm_pre,lstm_test=[],[]\n",
    "gru_pre,gru_test=[],[]\n",
    "bilstm_pre,bilstm_test=[],[]\n",
    "\n",
    "\n",
    "for siteId in sites:\n",
    "    print('\\n',siteId)\n",
    "    tmp = data[data['site']==siteId]\n",
    "    tmp = tmp.dropna()\n",
    "    tmp = tmp.reset_index()\n",
    "    if len(tmp) == 0:\n",
    "        #print('error',siteId)\n",
    "        continue\n",
    "    \n",
    "    index = len(tmp) * 0.80\n",
    "    train = tmp.loc[:index]\n",
    "    test = tmp.loc[index-1:]\n",
    "    len(train)/len(tmp) * 100 \n",
    "    \n",
    "    ### Normalise all data (simulated and real accidents dataset) and create lags.\n",
    "    train_norm, _ = normalise(features,train)\n",
    "    test_norm, _ = normalise(features,test)\n",
    "\n",
    "    # this is a binary classification thus we don't normlize the label\n",
    "    y_train = train_norm['state0']\n",
    "    x_train = train_norm[features]\n",
    "    y_test = test_norm['state0']\n",
    "    x_test = test_norm[features]\n",
    "\n",
    "    x_train_win, y_train_win = window_generator(x_train,y_train,lag,window)\n",
    "    x_test_win, y_test_win = window_generator(x_test,y_test,lag,window)\n",
    "\n",
    "    \n",
    "    print('RNN')\n",
    "    # RNN\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(3))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    model.fit(x_train_win, y_train_win, epochs=100, verbose=0)\n",
    "    y_pred = model.predict(x_test_win)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    rnn_pre.extend(y_pred.tolist())\n",
    "    rnn_test.extend(y_test_win.tolist())\n",
    "    \n",
    "    print('LSTM')\n",
    "    # LSTM\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(3))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    model.fit(x_train_win, y_train_win, epochs=100, verbose=0)\n",
    "    y_pred = model.predict(x_test_win)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    lstm_pre.extend(y_pred.tolist())\n",
    "    lstm_test.extend(y_test_win.tolist())\n",
    "    \n",
    "    print('BiLSTM')\n",
    "    # BiLSTM\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(3)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    model.fit(x_train_win, y_train_win, epochs=100, verbose=0)\n",
    "    y_pred = model.predict(x_test_win)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    bilstm_pre.extend(y_pred.tolist())\n",
    "    bilstm_test.extend(y_test_win.tolist())\n",
    "    \n",
    "    print('GRU')\n",
    "    # GRU\n",
    "    model = Sequential()\n",
    "    model.add(GRU(3))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    model.fit(x_train_win, y_train_win, epochs=100, verbose=0)\n",
    "    y_pred = model.predict(x_test_win)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    gru_pre.extend(y_pred.tolist())\n",
    "    gru_test.extend(y_test_win.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      9034\n",
      "           1       0.50      0.71      0.59       654\n",
      "\n",
      "    accuracy                           0.93      9688\n",
      "   macro avg       0.74      0.83      0.78      9688\n",
      "weighted avg       0.95      0.93      0.94      9688\n",
      "\n",
      "LSTM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98     17782\n",
      "           1       0.69      0.81      0.75      1594\n",
      "\n",
      "    accuracy                           0.95     19376\n",
      "   macro avg       0.84      0.89      0.86     19376\n",
      "weighted avg       0.96      0.95      0.96     19376\n",
      "\n",
      "BiLSTM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      8840\n",
      "           1       0.72      0.79      0.76       848\n",
      "\n",
      "    accuracy                           0.96      9688\n",
      "   macro avg       0.85      0.88      0.87      9688\n",
      "weighted avg       0.96      0.96      0.96      9688\n",
      "\n",
      "GRU\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      8868\n",
      "           1       0.73      0.82      0.77       820\n",
      "\n",
      "    accuracy                           0.96      9688\n",
      "   macro avg       0.86      0.90      0.87      9688\n",
      "weighted avg       0.96      0.96      0.96      9688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# methods = [('MRP',mrp_pre,mrp_test),('DL',dl_pre,dl_test),('LR',lr_pre,lr_test),('Random Forest',rf_pre,rf_test),('SVC',svc_pre,svc_test),('Kneighbours',kn_pre,kn_test),('xgb',xgb_pre,xgb_test)]\n",
    "# methods = [('LR',lr_pre,lr_test),('DL',dl_pre,dl_test),('SVC',svc_pre,svc_test),('xgb',xgb_pre,xgb_test),('MRP',mrp_pre,mrp_test)]\n",
    "# methods = [('xgb',xgb_pre,xgb_test)]\n",
    "methods = [('RNN',rnn_pre,rnn_test),('LSTM',lstm_pre,lstm_test),('BiLSTM',bilstm_pre,bilstm_test),('GRU',gru_pre,gru_test)]\n",
    "\n",
    "for method in methods:\n",
    "    print(method[0])\n",
    "    evaluation(method[1],method[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
